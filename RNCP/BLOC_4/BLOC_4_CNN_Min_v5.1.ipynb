{"cells":[{"cell_type":"markdown","metadata":{},"source":["## I.1. Install"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# # GOOGLE Colab ONLY : Mount GOOGLE Drive\n","from google.colab import drive\n","drive.mount(\"/content/drive\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import os\n","# GOOGLE Colab ONLY : Get & store the default work path\n","user_path = os.path.join(os.getcwd(), \"drive\", \"MyDrive\", \"Colab Notebooks\")\n","\n","# LOCAL : Get & store the current working path\n","# user_path = os.path.dirname(os.path.abspath(\"NoNeedFilename\"))\n","\n","print(user_path)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# requirements_filepath = os.path.join(user_path, \"requirements.txt\")\n","# !pip install -r {requirements_filepath}"]},{"cell_type":"markdown","metadata":{},"source":["## I.2. Libraries Import"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","\n","# Machine Learning\n","# import keras\n","from keras.models import Model\n","from keras.preprocessing.image import ImageDataGenerator\n","from keras.layers import Dense, Dropout, GlobalAveragePooling2D, BatchNormalization\n","from keras.optimizers import Adam, Nadam, SGD, RMSprop\n","from sklearn.metrics import confusion_matrix, classification_report, f1_score\n","\n","from keras.applications import EfficientNetB1, EfficientNetB2, EfficientNetB3, EfficientNetV2B1, EfficientNetV2B2, EfficientNetV2B3"]},{"cell_type":"markdown","metadata":{},"source":["## I.4. Image Processing"]},{"cell_type":"markdown","metadata":{},"source":["### I.4.2. Set Image Folder Path"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# GOOGLE Colab ONLY\n","train_dir = os.path.join(user_path, \"IMAGE_SPLIT\", \"train\")\n","val_dir = os.path.join(user_path, \"IMAGE_SPLIT\", \"val\")\n","test_dir = os.path.join(user_path, \"IMAGE_SPLIT\", \"test\")\n","\n","# LOCAL\n","# train_dir = r\"C:\\WORKSPACES\\DATA\\ML_DL\\IMAGE_SPLIT\\train\"\n","# val_dir = r\"C:\\WORKSPACES\\DATA\\ML_DL\\IMAGE_SPLIT\\val\"\n","# test_dir = r\"C:\\WORKSPACES\\DATA\\ML_DL\\IMAGE_SPLIT\\test\""]},{"cell_type":"markdown","metadata":{},"source":["### I.4.3. Data augmentation techniques"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["train_datagen = ImageDataGenerator(\n","    rescale = 1./255,\n","    shear_range = 0.2,\n","    rotation_range = 20,\n","    width_shift_range = 0.1,\n","    height_shift_range = 0.1,\n","    zoom_range = [0.9, 1.25],\n","    brightness_range = [0.5, 1.5],\n","    horizontal_flip = True,\n","    vertical_flip = True\n",")\n","\n","val_datagen = ImageDataGenerator(\n","    rescale = 1./255)\n","\n","test_datagen = ImageDataGenerator(\n","    rescale = 1./255)"]},{"cell_type":"markdown","metadata":{},"source":["### I.4.4. Setup Data generators"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Variables\n","batch_size = 32\n","height = 240\n","width = 240\n","image_shape = (height, width) # images of size 240x240 px with 3 color channels RGB automatically\n","\n","train_generator = train_datagen.flow_from_directory(\n","    train_dir,\n","    class_mode = \"categorical\",\n","    target_size = image_shape,\n","    batch_size = batch_size\n",")\n","\n","val_generator = val_datagen.flow_from_directory(\n","    val_dir,\n","    class_mode = \"categorical\",\n","    target_size = image_shape,\n","    batch_size = batch_size\n",")\n","\n","test_generator = test_datagen.flow_from_directory(\n","    test_dir,\n","    class_mode = \"categorical\",\n","    target_size = image_shape,\n","    batch_size = batch_size,\n","    shuffle = False\n",")"]},{"cell_type":"markdown","metadata":{},"source":["## II.1. Define variables and parameters"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from keras.metrics import Precision, Recall, F1Score, AUC\n","\n","# Model to use for transfer learning\n","model_name = \"EfficientNetV2B1\"\n","ModelNameFunc = globals()[model_name]\n","\n","# Work path\n","folder_name = f\"{model_name}_L1N128-DO5\"\n","work_path = os.path.join(user_path, folder_name)\n","\n","# Top Architecture for the new model\n","l1_neurons = 128                 # Number of neurons on layer 1 (deeper)\n","l1_activation = \"relu\"\n","dropout = 0.5                   # 0.2 - 0.5\n","l2_neurons = 32                 # Number of neurons on layer 2\n","l2_activation = \"relu\"\n","output_neurons = 3              # This layer will have 3 neurons or units fully connected. In line with our 3 classes.\n","output_activation = \"softmax\"\n","\n","# Metrics (parameter average = \"macro\" by default )\n","precision = Precision(name = \"Precision\")\n","recall = Recall(name = \"Recall\")\n","# auc = AUC(name = \"AUC\")\n","\n","# TRAIN : model.compile\n","compile_optimizer = \"Adam\"                  # Test : Nadam, RMSprop, SGD\n","compile_loss = \"categorical_crossentropy\"   # More than 2 classes, so categorical\n","compile_metrics = [\"accuracy\", precision, recall]   # auc\n","\n","# TRAIN : model.fit\n","epochs = 30\n","verbose = 1\n","\n","# FINE TUNE : model.compile\n","ft_compile_optimizer = Adam(learning_rate = 1e-5)\n","# ft_compile_optimizer : Very low learning rate. Test : Nadam, RMSprop, SGD\n","ft_compile_loss = \"categorical_crossentropy\"\n","ft_compile_metrics = [\"accuracy\", precision, recall]    # auc\n","\n","# FINE TUNE : model.fit\n","ft_epochs = 15\n","ft_verbose = 1\n","\n","# SAVE : File Path .h5\n","fileh5_path = os.path.join(work_path, f\"{folder_name}_H5_Model\", f\"{folder_name}_TRAIN_ManualSave.h5\")\n","ft_fileh5_path = os.path.join(work_path, f\"{folder_name}_H5_Model\", f\"{folder_name}_FT_ManualSave.h5\")"]},{"cell_type":"markdown","metadata":{},"source":["## II.2. Define optimizations"]},{"cell_type":"markdown","metadata":{},"source":["### II.2.1. Train optimizations (callbacks)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, TensorBoard, CSVLogger\n","\n","# Define the early stopping\n","early_stopping = EarlyStopping(\n","    monitor = \"val_loss\",        # Metric to monitor\n","    patience = 5,                # Number of epochs with no improvement  (around 10% of nb of epochs)\n","    verbose = 1,                 # Verbosity mode (0, 1, or 2)\n","    restore_best_weights = True  # Whether to restore model weights to the best epoch\n",")\n","\n","# Define the learning rate scheduler\n","lr_scheduler = ReduceLROnPlateau(\n","    monitor = \"val_loss\",       # Metric to monitor\n","    factor = 0.2,               # Factor by which to reduce the learning rate\n","    patience = 5,               # Number of epochs with no improvement (default = 10)\n","    verbose = 1,                # Verbosity mode (0, 1, or 2)\n","    min_lr = 1e-6               # Minimum learning rate\n",")\n","\n","# Define the model checkpoint callback\n","checkpoint = ModelCheckpoint(\n","    # filepath = os.path.join(work_path, f\"{model_name}_TRAIN_CheckPoint\"), # to use if don't wanna save to a .h5 or .keras file\n","    filepath = os.path.join(work_path, f\"{folder_name}_H5_Model\", f\"{folder_name}_TRAIN_MCPBest.h5\"),\n","    monitor = \"val_loss\",       # Metric to monitor\n","    save_freq = \"epoch\",        # Default = epoch\n","    save_weights_only = False,  # Default = False\n","    save_best_only = True,      # Save only if the monitored metric improves\n","    mode = \"min\",               # \"min\" if monitoring loss, \"max\" if monitoring accuracy\n","    verbose = 1                 # Verbosity mode (0, 1, or 2)\n",")\n","\n","# Define TensorBoard Logs\n","log_dir = os.path.join(work_path, f\"{folder_name}_LOGS_TRAIN\")\n","tensorboard = TensorBoard(\n","    log_dir = log_dir,\n","    write_graph = True,\n","    write_images = True,\n","    update_freq = \"epoch\"\n",")\n","\n","# Define CSVLogger\n","CSV_Log_filename = os.path.join(work_path, f\"{folder_name}_TRAIN.log\")\n","CSV_Logger = CSVLogger(\n","    CSV_Log_filename,\n","    separator = \"|\",\n","    append = False\n",")\n","\n","\n","\n","# Define the callbacks list\n","callbacks_list = [early_stopping, lr_scheduler, checkpoint, tensorboard, CSV_Logger]"]},{"cell_type":"markdown","metadata":{},"source":["### II.2.2. Fine Tune Optimization"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Define the FT Early stopping\n","ft_early_stopping = EarlyStopping(\n","    monitor = \"val_loss\",\n","    patience = 3,\n","    verbose = 1,                 # Verbosity mode (0, 1, or 2)\n","    restore_best_weights = True  # Whether to restore model weights to the best epoch\n",")\n","\n","# Define the FT Learning rate scheduler\n","ft_lr_scheduler = ReduceLROnPlateau(\n","    monitor = \"val_loss\",  # Metric to monitor\n","    factor = 0.2,          # Factor by which to reduce the learning rate\n","    patience = 3,          # Number of epochs with no improvement (default = 10)\n","    verbose = 1,           # Verbosity mode (0, 1, or 2)\n","    min_lr = 1e-6          # Minimum learning rate\n",")\n","\n","# Define the FT checkpoint callback\n","ft_checkpoint = ModelCheckpoint(\n","    # filepath = os.path.join(work_path, f\"{model_name}_FT_CheckPoint\"), # to use if don't wanna save to a .h5 or .keras file\n","    filepath = os.path.join(work_path, f\"{folder_name}_H5_Model\", f\"{folder_name}_FT_MCPBest.h5\"),\n","    monitor = \"val_loss\",       # Metric to monitor\n","    save_freq = \"epoch\",        # Default = epoch\n","    save_weights_only = False,  # Default = False\n","    save_best_only = True,      # Save only if the monitored metric improves\n","    mode = \"min\",               # \"min\" if monitoring loss, \"max\" if monitoring accuracy\n","    verbose = 1                 # Verbosity mode (0, 1, or 2)\n",")\n","\n","# Define the FT TensorBoard Logs\n","ft_log_dir = os.path.join(work_path, f\"{folder_name}_LOGS_FT\")\n","ft_tensorboard = TensorBoard(\n","    log_dir = ft_log_dir,\n","    write_graph=True,\n","    write_images=True,\n","    update_freq = \"epoch\"\n",")\n","\n","# Define the FT CSVLogger\n","ft_CSV_Log_filename = os.path.join(work_path, f\"{folder_name}FT.log\")\n","ft_CSV_Logger = CSVLogger(\n","    ft_CSV_Log_filename,\n","    separator = \"|\",\n","    append = False\n",")\n","\n","# Define the FT callbacks list\n","ft_callbacks_list = [ft_early_stopping, ft_lr_scheduler, ft_checkpoint, ft_tensorboard, ft_CSV_Logger]"]},{"cell_type":"markdown","metadata":{},"source":["## II.3. Pre train the model"]},{"cell_type":"markdown","metadata":{},"source":["### II.3.1. Instantiate a base model with pre-trained model and weights"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# First instantiate a base model with pre-trained weights\n","base_model = ModelNameFunc(\n","    include_top = False,\n","    weights = \"imagenet\",\n","    include_preprocessing = False, # ONLY for V2 model, otherwise put it as comment.\n","    input_shape = (height, width, output_neurons)\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["display(base_model.input)"]},{"cell_type":"markdown","metadata":{},"source":["### II.3.2. Define the new architecture on top"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["x = base_model.output\n","x = GlobalAveragePooling2D()(x) # Pooling\n","x = Dense(l1_neurons, activation = l1_activation)(x)\n","x = Dropout(dropout)(x)\n","x = Dense(l2_neurons, activation = l2_activation)(x)\n","x = BatchNormalization()(x)\n","\n","predictions = Dense(output_neurons, activation = output_activation)(x)\n","\n","model = Model(inputs = base_model.input, outputs = predictions)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print(model.input_shape)"]},{"cell_type":"markdown","metadata":{},"source":["### II.3.4. Compile the model"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":244,"status":"ok","timestamp":1695216970352,"user":{"displayName":"Quentin","userId":"05488577754205389272"},"user_tz":-120},"id":"CqwA0VQW3ztL"},"outputs":[],"source":["model.compile(\n","    optimizer = compile_optimizer,\n","    loss = compile_loss,\n","    metrics = compile_metrics\n",")"]},{"cell_type":"markdown","metadata":{},"source":["### II.3.5. Train the model\n","It's called \"history\" because it essentially keeps a historical record of various metrics and data related to how the model performed during training."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":1933103,"status":"error","timestamp":1695218914177,"user":{"displayName":"Quentin","userId":"05488577754205389272"},"user_tz":-120},"id":"adoTnFttVfmm","outputId":"1ab8bcb1-40ab-4142-ec67-cd5ca3fb14ee"},"outputs":[],"source":["history = model.fit(\n","    x = train_generator,\n","    steps_per_epoch = train_generator.samples // batch_size + 1,\n","    validation_data = val_generator,\n","    validation_steps = val_generator.samples // batch_size + 1,\n","    epochs = epochs,\n","    verbose = verbose,\n","    callbacks = callbacks_list\n",")\n","\n","# Save the model\n","model.save(fileh5_path)"]},{"cell_type":"markdown","metadata":{},"source":["### II.3.7. Evaluate Pre trained model"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Predict the values from the Test Dataset\n","Y_pred = model.predict(test_generator, steps = test_generator.samples // batch_size + 1)\n","\n","# Convert predictions classes from one hot vectors \n","Y_pred_classes = np.argmax(Y_pred, axis = 1)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Evaluate the model on the Test Dataset using `evaluate`\n","# f1 = F1Score(test_generator.classes, Y_pred_classes)\n","f1 = f1_score(test_generator.classes, Y_pred_classes, average = \"macro\")\n","# f1 = (2 * (precision * recall) / (precision + recall))\n","print(\"F1 Score : \", f1)\n","print(\"Evaluate on Test Data\")\n","results = model.evaluate(test_generator, batch_size = batch_size)"]},{"cell_type":"markdown","metadata":{},"source":["### II.3.8. Plot the Accuracy and the loss graphs"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":472},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1695041553774,"user":{"displayName":"Quentin","userId":"05488577754205389272"},"user_tz":-120},"id":"ZcYwDKRgbQ16","outputId":"e88138ed-fe1d-4b2b-ed97-40cbc3de00c8"},"outputs":[],"source":["# Plot the Loss graph\n","plt.plot(history.history[\"loss\"])\n","plt.plot(history.history[\"val_loss\"])\n","plt.title(\"Model Loss\")\n","plt.ylabel(\"Loss\")\n","plt.xlabel(\"Epoch\")\n","plt.legend([\"Train\", \"Val\"], loc = \"upper left\")\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":472},"executionInfo":{"elapsed":602,"status":"ok","timestamp":1695041694443,"user":{"displayName":"Quentin","userId":"05488577754205389272"},"user_tz":-120},"id":"jSetJ8JLaw0d","outputId":"5beca8d8-0b65-4f00-e8c5-9d64e4a6c819"},"outputs":[],"source":["# Plot the Accuracy graph\n","plt.plot(history.history[\"accuracy\"])\n","plt.plot(history.history[\"val_accuracy\"])\n","plt.title(\"Model Accuracy\")\n","plt.ylabel(\"Accuracy\")\n","plt.xlabel(\"Epoch\")\n","plt.legend([\"Train\", \"Val\"], loc = \"lower left\")\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["### II.3.8. Trained Model : Confusion Matrix"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# # Predict the values from the Test Dataset\n","# Y_pred = model.predict(test_generator, steps = test_generator.samples // batch_size + 1)\n","\n","# # Convert predictions classes from one hot vectors \n","# Y_pred_classes = np.argmax(Y_pred, axis = 1)\n","\n","# Convert validation observations from one hot vectors\n","# Y_true = np.argmax(test_generator.classes, axis = 1)\n","# OR\n","Y_true = test_generator.classes\n","\n","# Compute the confusion matrix\n","cm = confusion_matrix(Y_true, Y_pred_classes)\n","\n","# Print the confusion matrix\n","print(\"Confusion Matrix\")\n","print(cm)\n","\n","# Retrieve class names (label)\n","names_from_dir = sorted(os.listdir(val_dir))\n","dict(enumerate(names_from_dir))\n","#OR\n","class_names = list(val_generator.class_indices.keys())\n","# Check if the both are similar\n","print(names_from_dir == class_names)\n","\n","# Print the classification report\n","print(\"Classification Report\")\n","print(classification_report(Y_true, Y_pred_classes, target_names = class_names, digits = 4))\n"]},{"cell_type":"markdown","metadata":{},"source":["### II.3.9. Confusion Matrix Function"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def plot_confusion_matrix(\n","    cm,\n","    classes,\n","    normalize = False,\n","    title = \"Confusion matrix\",\n","    cmap = plt.cm.Blues):\n","    \"\"\"\n","    This function prints and plots the confusion matrix.\n","    Normalization can be applied by setting `normalize=True`.\n","    \"\"\"\n","    if normalize:\n","        cm = cm.astype(\"float\") / cm.sum(axis =1)[:, np.newaxis]\n","        print(\"Normalized confusion matrix\")\n","    else:\n","        print('Confusion matrix, without normalization')\n","\n","    print(cm)\n","    plt.imshow(cm, interpolation = \"nearest\", cmap = cmap)\n","    plt.title(title)\n","    plt.colorbar()\n","    plt.tight_layout()\n","    plt.ylabel(\"True label\")\n","    plt.xlabel(\"Predicted label\")"]},{"cell_type":"markdown","metadata":{},"source":["### II.3.10. Trained Model : Confusion Matrix Graph"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["plot_confusion_matrix(\n","    cm,\n","    class_names,\n","    normalize = True,\n","    title = \"Confusion matrix\",\n","    cmap = plt.cm.Blues\n","    )"]},{"cell_type":"markdown","metadata":{},"source":["## II.4. Fine Tuning\n","This requires unfreezing the base model and then recompiling the model (necessary for the changes to take effect), and then resuming training."]},{"cell_type":"markdown","metadata":{},"source":["### II.4.1. Unfreeze the base model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"g7Gja-vdVfmu"},"outputs":[],"source":["# Unfreeze the base model\n","base_model.trainable = True"]},{"cell_type":"markdown","metadata":{},"source":["### II.4.2. Re compile the model with a very low learning rate"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"znuOlyvHVfmu"},"outputs":[],"source":["# It's important to recompile your model after you make any changes\n","# to the `trainable` attribute of any inner layer, so that your changes\n","# are take into account\n","model.compile(\n","    optimizer = ft_compile_optimizer,\n","    loss = ft_compile_loss,\n","    metrics = ft_compile_metrics\n",")"]},{"cell_type":"markdown","metadata":{},"source":["### II.4.3. Retraining the model"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1956147,"status":"ok","timestamp":1695043662440,"user":{"displayName":"Quentin","userId":"05488577754205389272"},"user_tz":-120},"id":"D0BUO93kVfmv","outputId":"4d07373b-f0d5-44a2-e91b-ee4d2371ca84"},"outputs":[],"source":["# Resume training\n","ft_history = model.fit(\n","    x = train_generator,\n","    steps_per_epoch = train_generator.samples // batch_size + 1,\n","    validation_data = val_generator,\n","    validation_steps = val_generator.samples // batch_size + 1,\n","    epochs = ft_epochs,\n","    verbose = ft_verbose,\n","    callbacks = ft_callbacks_list\n",")\n","\n","# Save the Fine tuned model\n","model.save(ft_fileh5_path)"]},{"cell_type":"markdown","metadata":{},"source":["### II.4.4. Evaluation Fine Tune Model"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Evaluate the model on the Test Dataset using `evaluate`\n","# f1 = F1Score(test_generator.classes, Y_pred_classes)\n","ft_f1 = f1_score(test_generator.classes, Y_pred_classes, average = \"macro\")\n","print(\"F1 Score : \", ft_f1)\n","print(\"Evaluate on Test Data\")\n","ft_results = model.evaluate(test_generator, batch_size = batch_size)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Plot the Loss graph\n","plt.plot(ft_history.history[\"loss\"])\n","plt.plot(ft_history.history[\"val_loss\"])\n","plt.title(\"Model Loss\")\n","plt.ylabel(\"loss\")\n","plt.xlabel(\"epoch\")\n","plt.legend([\"Train\", \"Val\"], loc = \"upper left\")\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Plot the Accuracy graph\n","plt.plot(ft_history.history[\"accuracy\"])\n","plt.plot(ft_history.history[\"val_accuracy\"])\n","plt.title(\"Model Accuracy\")\n","plt.ylabel(\"Accuracy\")\n","plt.xlabel(\"Epoch\")\n","plt.legend([\"Train\", \"Val\"], loc = \"lower left\")\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["### II.4.5. Fine Tuned Model : Confusion Matrix"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# # Predict the values from the validation dataset\n","# Y_pred = model.predict(test_generator, steps = test_generator.samples // batch_size + 1)\n","\n","# # Convert predictions classes from one hot vectors \n","# Y_pred_classes = np.argmax(Y_pred, axis = 1)\n","\n","# Convert validation observations from one hot vectors\n","# Y_true = np.argmax(test_generator.classes, axis = 1)\n","# OR\n","Y_true = test_generator.classes\n","\n","# Compute the confusion matrix\n","ft_cm = confusion_matrix(Y_true, Y_pred_classes)\n","\n","# Print the confusion matrix\n","print(\"Confusion Matrix\")\n","print(ft_cm)\n","\n","# Retrieve class names (label)\n","names_from_dir = sorted(os.listdir(val_dir))\n","dict(enumerate(names_from_dir))\n","#OR\n","class_names = list(val_generator.class_indices.keys())\n","# Check if the both are similar\n","print(names_from_dir == class_names)\n","\n","# Print the classification report\n","print(\"Classification Report\")\n","print(classification_report(Y_true, Y_pred_classes, target_names = class_names, digits = 4))"]},{"cell_type":"markdown","metadata":{},"source":["### II.4.5. Fine Tuned Model : Confusion Matrix Graph"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":575},"executionInfo":{"elapsed":802,"status":"ok","timestamp":1695043686140,"user":{"displayName":"Quentin","userId":"05488577754205389272"},"user_tz":-120},"id":"J69Fg9hzVfm3","outputId":"8ae39da7-76e7-47a4-d03b-771a91047633"},"outputs":[],"source":["plot_confusion_matrix(ft_cm,\n","                      class_names,\n","                      normalize = True,\n","                      title = \"Confusion matrix\",\n","                      cmap = plt.cm.Blues\n","                      )"]},{"cell_type":"markdown","metadata":{},"source":["### II.4.6. Some metrics of Fine Tune Model\n","```py\n","Normalement pas besoin car keras.metrics nous donne les infos avec le `results = model.evaluate(test_generator, batch_size = batch_size)`. (average = \"macro\" par défaut)\n","```"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gikmVZURVfm3","outputId":"eaa3f7c0-3f15-41df-aaf4-b7bd2b3df2bd"},"outputs":[],"source":["from sklearn.metrics import precision_score, recall_score, f1_score\n","\n","# Calcul de la précision\n","precision = precision_score(test_generator.classes, Y_pred_classes, average='macro') # average macro, calcul individuel par classe attribut le même poids à chaque classe\n","# Calcul du recall\n","recall = recall_score(test_generator.classes, Y_pred_classes, average='macro')\n","\n","# Calcul du F1 score\n","f1 = f1_score(test_generator.classes, Y_pred_classes, average='macro')\n","\n","# Affichage des résultats\n","print(\"Précision :\", precision)\n","print(\"Recall :\", recall)\n","print(\"F1 score :\", f1)"]},{"cell_type":"markdown","metadata":{},"source":["# III. READ LOGS"]},{"cell_type":"markdown","metadata":{},"source":["## III.1. TRAIN"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["%load_ext tensorboard\n","%tensorboard --logdir log_dir"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{},"source":["## III.2. FINE TUNE"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["%load_ext tensorboard\n","%tensorboard --logdir ft_log_dir"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"}},"nbformat":4,"nbformat_minor":0}
